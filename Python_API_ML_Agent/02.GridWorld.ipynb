{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import datetime\n",
    "import platform\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import deque\n",
    "from mlagents_envs.environment import UnityEnvironment, ActionTuple\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = [3*2, 64, 84]\n",
    "action_size = 4\n",
    "\n",
    "load_model = False\n",
    "train_model = True\n",
    "\n",
    "batch_size = 32\n",
    "mem_maxlen = 10000\n",
    "discount_factor = 0.9\n",
    "learning_rate = 0.00025\n",
    "\n",
    "run_step = 50000 if train_model else 0\n",
    "test_step = 5000\n",
    "train_start_step = 5000\n",
    "target_update_step = 500\n",
    "\n",
    "print_interval = 10\n",
    "save_interval = 100\n",
    "\n",
    "epsilon_eval = 0.05\n",
    "epsilon_init = 1.0 if train_model else epsilon_eval\n",
    "epsilon_min = 0.1\n",
    "explore_step = run_step * 0.8\n",
    "epsilon_delta = (epsilon_init - epsilon_min) / explore_step if train_model else 0\n",
    "\n",
    "VISUAL_OBS = 0\n",
    "GOAL_OBS = 1\n",
    "VECTOR_OBS = 2\n",
    "OBS = VISUAL_OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Windows\n"
     ]
    }
   ],
   "source": [
    "game = 'grid'\n",
    "os_name = platform.system()\n",
    "if os_name == 'Windows':\n",
    "    env_name = f'../ML_Agents_Project/env/{game}'\n",
    "\n",
    "date_time = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "save_path = f'./saved_models/{game}/DQN/{date_time}'\n",
    "load_path = f'./saved_models/{game}/DQN/202302211540'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(os_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DQN, self).__init__(**kwargs)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=state_size[0], out_channels=32, kernel_size=8, stride=4)\n",
    "        dim1 = ((state_size[1] - 8) // 4 + 1, (state_size[2] - 8) // 4 + 1)\n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
    "        dim2 = ((dim1[0] - 4) // 2 + 1, (dim1[1] - 4) // 2 + 1)\n",
    "        self.conv3 = torch.nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "        dim3 = ((dim2[0] - 3) // 1 + 1, (dim2[1] - 3) // 1 + 1)\n",
    "\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(64*dim3[0] * dim3[1], 512)\n",
    "        self.q = torch.nn.Linear(512, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.flat(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.q(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.network = DQN().to(device)\n",
    "        self.target_network = copy.deepcopy(self.network)\n",
    "        self.optimizer = torch.optim.Adam(self.network.parameters(), lr=learning_rate, )\n",
    "        self.memory = deque(maxlen=mem_maxlen)\n",
    "        self.epsilon = epsilon_init\n",
    "        self.writer = SummaryWriter(save_path)\n",
    "\n",
    "        if load_model == True:\n",
    "            print(f\"... Load Model from {load_path} / ckpt...\")\n",
    "            checkpoint = torch.load(load_path+'/ckpt', map_location=device)\n",
    "            self.network.load_state_dict(checkpoint['network'])\n",
    "            self.target_network.load_state_dict(checkpoint['network'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "    def get_action(self, state, training=True):\n",
    "        # 네트워크 모드 설정\n",
    "        self.network.trian(training)\n",
    "        epsilon = self.epsilon if training else epsilon_eval\n",
    "\n",
    "        # 랜덤하게 행동 결정\n",
    "        if epsilon > random.random():\n",
    "            action = np.random.randint(0, action_size, size=(state.shape[0], 1))\n",
    "        \n",
    "        # 네트워크 연산에 따라 행동 결정\n",
    "        else:\n",
    "            q = self.network(torch.FloatTensor(state).to(device))\n",
    "            action = torch.argmax(q, axis=1, keepdim=True).data.cpu().numpy()\n",
    "        return action\n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def train_model(self):\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        state = np.stack([b[0] for b in batch], axis=0)\n",
    "        action = np.stack([b[1] for b in batch], axis=0)\n",
    "        reward = np.stack([b[2] for b in batch], axis=0)\n",
    "        next_state = np.stack([b[3] for b in batch], axis=0)\n",
    "        done = np.stack([b[4] for b in batch], axis=0)\n",
    "\n",
    "        state, action, reward, next_state, done = map(lambda x:torch.FloatTensor(x).to(device), [state, action, reward, next_state, done])\n",
    "\n",
    "        eye = torch.eye(action_size).to(device)\n",
    "        one_hot_action = eye[action.view(-1).long()]\n",
    "        q = (self.network(state) * one_hot_action).sum(1, keepdims=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_q = self.target_network(next_state)\n",
    "            target_q = reward + next_q.max(1, keepdims=True).values * ((1-done) * discount_factor)\n",
    "\n",
    "            loss = F.smooth_l1_loss(q, target_q)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.epsilon = max(epsilon_min, self.epsilon - epsilon_delta)\n",
    "\n",
    "            return loss.item()\n",
    "    \n",
    "    def update_target(self):\n",
    "        self.target_network.load_state_dict(self.network.state_dict())\n",
    "\n",
    "    def save_model(self):\n",
    "        print(f'... save model to {save_path}/ckpt ...')\n",
    "        torch.save({'network' : self.network.state_dict(), 'optimizer' : self.optimizer.state_dict()}, save_path+'/ckpt')\n",
    "\n",
    "    def writer_summray(self, score, loss, epsilon, step):\n",
    "        self.writer.add_scalar('run/score', score, step)\n",
    "        self.writer.add_scalar('model/loss', loss, step)\n",
    "        self.writer.add_scalar('model/epsilon', epsilon, step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Environment timed out shutting down. Killing...\n"
     ]
    },
    {
     "ename": "UnityTimeOutException",
     "evalue": "The Unity environment took too long to respond. Make sure that :\n\t The environment does not need user interaction to launch\n\t The Agents' Behavior Parameters > Behavior Type is set to \"Default\"\n\t The environment and the Python interface have compatible versions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnityTimeOutException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27372\\3774836501.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mengine_configuration_channel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEngineConfigurationChannel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m env = UnityEnvironment(file_name=env_name, side_channels=[\n\u001b[1;32m----> 3\u001b[1;33m                        engine_configuration_channel])\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aqs45\\anaconda3\\envs\\rl3.7\\lib\\site-packages\\mlagents_envs\\environment.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file_name, worker_id, base_port, seed, no_graphics, timeout_wait, additional_args, side_channels, log_folder)\u001b[0m\n\u001b[0;32m    221\u001b[0m         )\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m             \u001b[0maca_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_academy_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl_init_parameters_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m             \u001b[0maca_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maca_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrl_initialization_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUnityTimeOutException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aqs45\\anaconda3\\envs\\rl3.7\\lib\\site-packages\\mlagents_envs\\environment.py\u001b[0m in \u001b[0;36m_send_academy_parameters\u001b[1;34m(self, init_parameters)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnityInputProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrl_initialization_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_communicator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll_process\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aqs45\\anaconda3\\envs\\rl3.7\\lib\\site-packages\\mlagents_envs\\rpc_communicator.py\u001b[0m in \u001b[0;36minitialize\u001b[1;34m(self, inputs, poll_callback)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnityInputProto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoll_callback\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPollCallback\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     ) -> UnityOutputProto:\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll_for_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoll_callback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0maca_param\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munity_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnityMessageProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aqs45\\anaconda3\\envs\\rl3.7\\lib\\site-packages\\mlagents_envs\\rpc_communicator.py\u001b[0m in \u001b[0;36mpoll_for_timeout\u001b[1;34m(self, poll_callback)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# Got this far without reading any data from the connection, so it must be dead.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         raise UnityTimeOutException(\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;34m\"The Unity environment took too long to respond. Make sure that :\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[1;34m\"\\t The environment does not need user interaction to launch\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;34m'\\t The Agents\\' Behavior Parameters > Behavior Type is set to \"Default\"\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnityTimeOutException\u001b[0m: The Unity environment took too long to respond. Make sure that :\n\t The environment does not need user interaction to launch\n\t The Agents' Behavior Parameters > Behavior Type is set to \"Default\"\n\t The environment and the Python interface have compatible versions."
     ]
    }
   ],
   "source": [
    "engine_configuration_channel = EngineConfigurationChannel()\n",
    "env = UnityEnvironment(file_name=env_name, side_channels=[\n",
    "                       engine_configuration_channel])\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27372\\1348913687.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnityEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mside_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine_configuration_channel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env_name' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc26d70c6e128a07817bbba1f59a251f2553834b2ee684a298c5157c7ffc3573"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
