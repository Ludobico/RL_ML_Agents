# ML_Agents에서 제공하는 강화학습 알고리즘

현재 ML_Agents에서는 다음과 같은 알고리즘들을 제공합니다. 제공하는 알고리즘에는 알고리즘뿐 아니라 모방학습(Imitation learning) 알고리즘도 있습니다.

# 강화학습(Reinforcement learning)

- Proximal Policy Optimization(PPO)

- Soft Actor Critic(SAC)

- Curiosity based Exploration(ICM, RND)

- Multi-Agent Posthumous Credit Assignment(MA-POCA)

# 모방학습(Imitation learning)

- Behavioral Cloning(BC)

- Generative Adversarial Imitation Learning(GAIL)

## PPO와 SAC

먼저 강화학습 알고리즘으로는 일반적인 강화학습 알고리즘인 Proximal Policy Optimization(PPO)와 Soft Actor Critic(SAC)을 제공합니다. 해당 알고리즘들은 강화학습에서 가장 대중적으로 사용되는 알고리즘들로 일반적으로 좋은 성능을 보이며 안정적으로 학습됩니다. 또한 연속적인 행동과 이산적인 행동 환경 모두에서 사용할 수 있습니다.

## ICM, RND

다른 알고리즘들의 경우 특수한 문제를 풀기 위한 강화학습 알고리즘들입니다. 먼저 ICM과 RND 알고리즘은 `호기심 기반 탐험을 위한 알고리즘`으로 강화학습의 탐험에 대한 성능을 향상시킨 알고리즘입니다. 해당 알고리즘은 Hard exploration 문제들, 즉 보상을 얻디까지 복잡한 탐험을 수행해야하는 문제를 풀기 위한 특수한 알고리즘입니다.

## MA-POCA

마지막 MA-POCA 알고리즘은 멀티 에이전트 환경, 즉 하나의 환경에 다수의 에이전트가 존재하는 환경에서 학습을 수행하는 알고리즘입니다. 해당 알고리즘의 경우 여러 에이전트가 효율적으로 협력하여 일부 희생을 하더라도 `공동의 목표를 수행`하도록 학습하는 알고리즘입니다.

## BC와 GAIL

다음으로 모방학습은 강화학습과는 학습 방법이 다릅니다. 모방학습 알고리즘은 `사람의 플레이 데이터를 기반`으로 에이전트가 사람의 플레이를 모방하도록 학습하는 알고리즘입니다. 여기서는 단순히 지도학습처럼 사람의 행동을 모방하는 Behavioral Cloning과 Generative Adversarial Network(GAN) 방식을 도입한 Generative Adversarial Imitation Learining, 줄여서 GAIL 알고리즘을 제공합니다.
